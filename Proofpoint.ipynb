{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Proofpoint.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "D8xFuWWZ0Z5A",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Mounting drive and adjustments"
      ]
    },
    {
      "metadata": {
        "id": "wjns-AOa40fA",
        "colab_type": "code",
        "outputId": "58400be7-4946-4a2d-f375-eeb8b34e2c8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NYtc4ArV5RfK",
        "colab_type": "code",
        "outputId": "ee4e786f-8065-4988-d696-76531b8f15fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "#Change working directory to make it easier to access the files\n",
        "import os\n",
        "os.chdir(\"/content/gdrive/My Drive/Colab Notebooks/proofpoint\")\n",
        "os.getcwd() "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/My Drive/Colab Notebooks/proofpoint'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "3xzV--qd5o5m",
        "colab_type": "code",
        "outputId": "6ec59a88-5b95-4c93-ce6d-2ab2a2f85cf9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "#Import libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, BatchNormalization, Activation\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "import csv\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.optimizers import SGD, Adam, RMSprop, Adagrad, Adamax\n",
        "from keras.callbacks import ModelCheckpoint\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "yESn77mP0uIT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Loading the data"
      ]
    },
    {
      "metadata": {
        "id": "_TwvH9QV5Vfk",
        "colab_type": "code",
        "outputId": "cf701f88-6fc1-444a-ad49-ddf67f049902",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "features_dataset=pd.read_csv('train_features.csv', header=None)\n",
        "labels_dataset=pd.read_csv('train_labels.csv', header=None)\n",
        "print('Features dataset shape is: ' + str(features_dataset.shape))\n",
        "print('Labels dataset shape is: '+ str(labels_dataset.shape))"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Features dataset shape is: (140, 903)\n",
            "Labels dataset shape is: (140, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "z1Lw2HgQ0zsI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data exploration"
      ]
    },
    {
      "metadata": {
        "id": "nLwuOCP752V_",
        "colab_type": "code",
        "outputId": "f5c2ff72-9dae-42b8-a76e-ec1d892c58c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        }
      },
      "cell_type": "code",
      "source": [
        "features_dataset.describe()"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>...</th>\n",
              "      <th>893</th>\n",
              "      <th>894</th>\n",
              "      <th>895</th>\n",
              "      <th>896</th>\n",
              "      <th>897</th>\n",
              "      <th>898</th>\n",
              "      <th>899</th>\n",
              "      <th>900</th>\n",
              "      <th>901</th>\n",
              "      <th>902</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>140.000000</td>\n",
              "      <td>140.000000</td>\n",
              "      <td>140.000000</td>\n",
              "      <td>140.000000</td>\n",
              "      <td>140.000000</td>\n",
              "      <td>140.000000</td>\n",
              "      <td>140.000000</td>\n",
              "      <td>140.000000</td>\n",
              "      <td>140.000000</td>\n",
              "      <td>140.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>140.000000</td>\n",
              "      <td>140.000000</td>\n",
              "      <td>140.000000</td>\n",
              "      <td>140.000000</td>\n",
              "      <td>140.000000</td>\n",
              "      <td>140.000000</td>\n",
              "      <td>140.000000</td>\n",
              "      <td>140.000000</td>\n",
              "      <td>140.000000</td>\n",
              "      <td>140.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>-3.706226</td>\n",
              "      <td>0.620541</td>\n",
              "      <td>-0.691226</td>\n",
              "      <td>-2.883438</td>\n",
              "      <td>0.798445</td>\n",
              "      <td>0.276561</td>\n",
              "      <td>0.382528</td>\n",
              "      <td>-0.890959</td>\n",
              "      <td>-1.694734</td>\n",
              "      <td>-0.719966</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.508409</td>\n",
              "      <td>-1.576743</td>\n",
              "      <td>0.190566</td>\n",
              "      <td>0.665053</td>\n",
              "      <td>-0.774684</td>\n",
              "      <td>0.931779</td>\n",
              "      <td>0.791181</td>\n",
              "      <td>-0.458641</td>\n",
              "      <td>0.723416</td>\n",
              "      <td>-0.132218</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>4.064704</td>\n",
              "      <td>3.014747</td>\n",
              "      <td>3.295262</td>\n",
              "      <td>3.331956</td>\n",
              "      <td>3.484214</td>\n",
              "      <td>3.203680</td>\n",
              "      <td>3.114446</td>\n",
              "      <td>3.221021</td>\n",
              "      <td>3.639898</td>\n",
              "      <td>3.124935</td>\n",
              "      <td>...</td>\n",
              "      <td>3.125331</td>\n",
              "      <td>3.262723</td>\n",
              "      <td>3.429600</td>\n",
              "      <td>3.092077</td>\n",
              "      <td>3.462897</td>\n",
              "      <td>3.301253</td>\n",
              "      <td>3.131848</td>\n",
              "      <td>2.616963</td>\n",
              "      <td>3.382829</td>\n",
              "      <td>3.657816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-12.753200</td>\n",
              "      <td>-8.020900</td>\n",
              "      <td>-9.688800</td>\n",
              "      <td>-10.540100</td>\n",
              "      <td>-8.493400</td>\n",
              "      <td>-6.525400</td>\n",
              "      <td>-8.397000</td>\n",
              "      <td>-8.372300</td>\n",
              "      <td>-10.153200</td>\n",
              "      <td>-10.185400</td>\n",
              "      <td>...</td>\n",
              "      <td>-8.152700</td>\n",
              "      <td>-10.229800</td>\n",
              "      <td>-8.713400</td>\n",
              "      <td>-9.106600</td>\n",
              "      <td>-11.294900</td>\n",
              "      <td>-7.695700</td>\n",
              "      <td>-7.090500</td>\n",
              "      <td>-6.851600</td>\n",
              "      <td>-6.184400</td>\n",
              "      <td>-9.723500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-6.393700</td>\n",
              "      <td>-1.665500</td>\n",
              "      <td>-2.625975</td>\n",
              "      <td>-5.215000</td>\n",
              "      <td>-1.934025</td>\n",
              "      <td>-1.833875</td>\n",
              "      <td>-1.871550</td>\n",
              "      <td>-2.941725</td>\n",
              "      <td>-3.986725</td>\n",
              "      <td>-2.876275</td>\n",
              "      <td>...</td>\n",
              "      <td>-3.739425</td>\n",
              "      <td>-3.837325</td>\n",
              "      <td>-2.248525</td>\n",
              "      <td>-1.361275</td>\n",
              "      <td>-3.141325</td>\n",
              "      <td>-0.960575</td>\n",
              "      <td>-1.299400</td>\n",
              "      <td>-2.491375</td>\n",
              "      <td>-1.769575</td>\n",
              "      <td>-2.728575</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>-4.022400</td>\n",
              "      <td>0.559550</td>\n",
              "      <td>-0.651150</td>\n",
              "      <td>-3.022050</td>\n",
              "      <td>1.005600</td>\n",
              "      <td>0.309250</td>\n",
              "      <td>0.454450</td>\n",
              "      <td>-0.826550</td>\n",
              "      <td>-1.664150</td>\n",
              "      <td>-0.940650</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.873850</td>\n",
              "      <td>-1.594600</td>\n",
              "      <td>0.274000</td>\n",
              "      <td>0.456750</td>\n",
              "      <td>-1.232550</td>\n",
              "      <td>1.210100</td>\n",
              "      <td>0.785650</td>\n",
              "      <td>-0.055900</td>\n",
              "      <td>0.350250</td>\n",
              "      <td>0.200050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>-0.860025</td>\n",
              "      <td>2.784550</td>\n",
              "      <td>1.432475</td>\n",
              "      <td>-0.441100</td>\n",
              "      <td>3.353100</td>\n",
              "      <td>2.432525</td>\n",
              "      <td>2.270475</td>\n",
              "      <td>1.324300</td>\n",
              "      <td>0.575900</td>\n",
              "      <td>1.441625</td>\n",
              "      <td>...</td>\n",
              "      <td>0.490925</td>\n",
              "      <td>0.554300</td>\n",
              "      <td>2.449825</td>\n",
              "      <td>2.790450</td>\n",
              "      <td>1.842575</td>\n",
              "      <td>3.121575</td>\n",
              "      <td>2.618375</td>\n",
              "      <td>1.136900</td>\n",
              "      <td>3.384000</td>\n",
              "      <td>2.175950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>7.862500</td>\n",
              "      <td>9.077900</td>\n",
              "      <td>7.729800</td>\n",
              "      <td>5.230100</td>\n",
              "      <td>10.856000</td>\n",
              "      <td>8.125200</td>\n",
              "      <td>9.032900</td>\n",
              "      <td>8.249100</td>\n",
              "      <td>7.994100</td>\n",
              "      <td>7.576900</td>\n",
              "      <td>...</td>\n",
              "      <td>7.073000</td>\n",
              "      <td>6.822000</td>\n",
              "      <td>11.433600</td>\n",
              "      <td>9.259000</td>\n",
              "      <td>7.385900</td>\n",
              "      <td>12.639000</td>\n",
              "      <td>9.713000</td>\n",
              "      <td>5.019900</td>\n",
              "      <td>8.439900</td>\n",
              "      <td>9.632300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 900 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              3           4           5           6           7           8    \\\n",
              "count  140.000000  140.000000  140.000000  140.000000  140.000000  140.000000   \n",
              "mean    -3.706226    0.620541   -0.691226   -2.883438    0.798445    0.276561   \n",
              "std      4.064704    3.014747    3.295262    3.331956    3.484214    3.203680   \n",
              "min    -12.753200   -8.020900   -9.688800  -10.540100   -8.493400   -6.525400   \n",
              "25%     -6.393700   -1.665500   -2.625975   -5.215000   -1.934025   -1.833875   \n",
              "50%     -4.022400    0.559550   -0.651150   -3.022050    1.005600    0.309250   \n",
              "75%     -0.860025    2.784550    1.432475   -0.441100    3.353100    2.432525   \n",
              "max      7.862500    9.077900    7.729800    5.230100   10.856000    8.125200   \n",
              "\n",
              "              9           10          11          12      ...             893  \\\n",
              "count  140.000000  140.000000  140.000000  140.000000     ...      140.000000   \n",
              "mean     0.382528   -0.890959   -1.694734   -0.719966     ...       -1.508409   \n",
              "std      3.114446    3.221021    3.639898    3.124935     ...        3.125331   \n",
              "min     -8.397000   -8.372300  -10.153200  -10.185400     ...       -8.152700   \n",
              "25%     -1.871550   -2.941725   -3.986725   -2.876275     ...       -3.739425   \n",
              "50%      0.454450   -0.826550   -1.664150   -0.940650     ...       -1.873850   \n",
              "75%      2.270475    1.324300    0.575900    1.441625     ...        0.490925   \n",
              "max      9.032900    8.249100    7.994100    7.576900     ...        7.073000   \n",
              "\n",
              "              894         895         896         897         898         899  \\\n",
              "count  140.000000  140.000000  140.000000  140.000000  140.000000  140.000000   \n",
              "mean    -1.576743    0.190566    0.665053   -0.774684    0.931779    0.791181   \n",
              "std      3.262723    3.429600    3.092077    3.462897    3.301253    3.131848   \n",
              "min    -10.229800   -8.713400   -9.106600  -11.294900   -7.695700   -7.090500   \n",
              "25%     -3.837325   -2.248525   -1.361275   -3.141325   -0.960575   -1.299400   \n",
              "50%     -1.594600    0.274000    0.456750   -1.232550    1.210100    0.785650   \n",
              "75%      0.554300    2.449825    2.790450    1.842575    3.121575    2.618375   \n",
              "max      6.822000   11.433600    9.259000    7.385900   12.639000    9.713000   \n",
              "\n",
              "              900         901         902  \n",
              "count  140.000000  140.000000  140.000000  \n",
              "mean    -0.458641    0.723416   -0.132218  \n",
              "std      2.616963    3.382829    3.657816  \n",
              "min     -6.851600   -6.184400   -9.723500  \n",
              "25%     -2.491375   -1.769575   -2.728575  \n",
              "50%     -0.055900    0.350250    0.200050  \n",
              "75%      1.136900    3.384000    2.175950  \n",
              "max      5.019900    8.439900    9.632300  \n",
              "\n",
              "[8 rows x 900 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "metadata": {
        "id": "xQqbvFvP7sgZ",
        "colab_type": "code",
        "outputId": "0749129e-ff83-4ad8-aa66-5dc69882ef57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        }
      },
      "cell_type": "code",
      "source": [
        "features_dataset.head()"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>893</th>\n",
              "      <th>894</th>\n",
              "      <th>895</th>\n",
              "      <th>896</th>\n",
              "      <th>897</th>\n",
              "      <th>898</th>\n",
              "      <th>899</th>\n",
              "      <th>900</th>\n",
              "      <th>901</th>\n",
              "      <th>902</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>right</td>\n",
              "      <td>type_3</td>\n",
              "      <td>green</td>\n",
              "      <td>0.8827</td>\n",
              "      <td>3.2917</td>\n",
              "      <td>1.4651</td>\n",
              "      <td>-4.5278</td>\n",
              "      <td>1.0490</td>\n",
              "      <td>2.3398</td>\n",
              "      <td>1.8729</td>\n",
              "      <td>...</td>\n",
              "      <td>0.8854</td>\n",
              "      <td>-0.8752</td>\n",
              "      <td>0.2662</td>\n",
              "      <td>4.9686</td>\n",
              "      <td>2.5588</td>\n",
              "      <td>-0.6121</td>\n",
              "      <td>-3.3692</td>\n",
              "      <td>0.0550</td>\n",
              "      <td>-1.5296</td>\n",
              "      <td>-5.3041</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>left</td>\n",
              "      <td>type_2</td>\n",
              "      <td>blue</td>\n",
              "      <td>1.4458</td>\n",
              "      <td>-2.9575</td>\n",
              "      <td>-1.2341</td>\n",
              "      <td>-3.9684</td>\n",
              "      <td>-2.7645</td>\n",
              "      <td>5.6346</td>\n",
              "      <td>1.7838</td>\n",
              "      <td>...</td>\n",
              "      <td>-4.3774</td>\n",
              "      <td>-2.2512</td>\n",
              "      <td>-1.6331</td>\n",
              "      <td>7.2724</td>\n",
              "      <td>1.7616</td>\n",
              "      <td>4.2826</td>\n",
              "      <td>5.5557</td>\n",
              "      <td>1.0588</td>\n",
              "      <td>2.6734</td>\n",
              "      <td>-4.5224</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>right</td>\n",
              "      <td>type_2</td>\n",
              "      <td>green</td>\n",
              "      <td>-10.2982</td>\n",
              "      <td>-0.3714</td>\n",
              "      <td>-0.9886</td>\n",
              "      <td>-3.2219</td>\n",
              "      <td>4.0925</td>\n",
              "      <td>-0.8319</td>\n",
              "      <td>-3.0588</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.4408</td>\n",
              "      <td>-2.5580</td>\n",
              "      <td>-1.2116</td>\n",
              "      <td>5.1098</td>\n",
              "      <td>-0.6747</td>\n",
              "      <td>-1.2528</td>\n",
              "      <td>-2.2944</td>\n",
              "      <td>-3.4745</td>\n",
              "      <td>2.8633</td>\n",
              "      <td>1.6737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>right</td>\n",
              "      <td>type_1</td>\n",
              "      <td>red</td>\n",
              "      <td>-8.4566</td>\n",
              "      <td>-0.2408</td>\n",
              "      <td>-3.0342</td>\n",
              "      <td>2.9534</td>\n",
              "      <td>2.8977</td>\n",
              "      <td>0.8851</td>\n",
              "      <td>3.0113</td>\n",
              "      <td>...</td>\n",
              "      <td>0.9434</td>\n",
              "      <td>-0.8771</td>\n",
              "      <td>0.4143</td>\n",
              "      <td>4.3368</td>\n",
              "      <td>-11.2949</td>\n",
              "      <td>-7.4289</td>\n",
              "      <td>7.9900</td>\n",
              "      <td>-6.2433</td>\n",
              "      <td>1.6592</td>\n",
              "      <td>-4.8601</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>left</td>\n",
              "      <td>type_1</td>\n",
              "      <td>blue</td>\n",
              "      <td>4.2681</td>\n",
              "      <td>-2.2052</td>\n",
              "      <td>-5.9093</td>\n",
              "      <td>0.1036</td>\n",
              "      <td>1.8462</td>\n",
              "      <td>1.9801</td>\n",
              "      <td>2.1129</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.2290</td>\n",
              "      <td>0.5390</td>\n",
              "      <td>0.7648</td>\n",
              "      <td>1.1348</td>\n",
              "      <td>1.9829</td>\n",
              "      <td>3.7682</td>\n",
              "      <td>-1.7092</td>\n",
              "      <td>1.4791</td>\n",
              "      <td>5.7732</td>\n",
              "      <td>-3.9106</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 903 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     0       1      2        3       4       5       6       7       8    \\\n",
              "0  right  type_3  green   0.8827  3.2917  1.4651 -4.5278  1.0490  2.3398   \n",
              "1   left  type_2   blue   1.4458 -2.9575 -1.2341 -3.9684 -2.7645  5.6346   \n",
              "2  right  type_2  green -10.2982 -0.3714 -0.9886 -3.2219  4.0925 -0.8319   \n",
              "3  right  type_1    red  -8.4566 -0.2408 -3.0342  2.9534  2.8977  0.8851   \n",
              "4   left  type_1   blue   4.2681 -2.2052 -5.9093  0.1036  1.8462  1.9801   \n",
              "\n",
              "      9     ...       893     894     895     896      897     898     899  \\\n",
              "0  1.8729   ...    0.8854 -0.8752  0.2662  4.9686   2.5588 -0.6121 -3.3692   \n",
              "1  1.7838   ...   -4.3774 -2.2512 -1.6331  7.2724   1.7616  4.2826  5.5557   \n",
              "2 -3.0588   ...   -1.4408 -2.5580 -1.2116  5.1098  -0.6747 -1.2528 -2.2944   \n",
              "3  3.0113   ...    0.9434 -0.8771  0.4143  4.3368 -11.2949 -7.4289  7.9900   \n",
              "4  2.1129   ...   -0.2290  0.5390  0.7648  1.1348   1.9829  3.7682 -1.7092   \n",
              "\n",
              "      900     901     902  \n",
              "0  0.0550 -1.5296 -5.3041  \n",
              "1  1.0588  2.6734 -4.5224  \n",
              "2 -3.4745  2.8633  1.6737  \n",
              "3 -6.2433  1.6592 -4.8601  \n",
              "4  1.4791  5.7732 -3.9106  \n",
              "\n",
              "[5 rows x 903 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "metadata": {
        "id": "KmNyNQIA7tni",
        "colab_type": "code",
        "outputId": "1cf7004c-c82c-493f-a431-ff147d3c5582",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "features_dataset.isnull().values.any() #check for missing values"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "metadata": {
        "id": "U9v45VdEZKcq",
        "colab_type": "code",
        "outputId": "de0a708a-ab62-4870-82da-7157eedeeab9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        }
      },
      "cell_type": "code",
      "source": [
        "#Counting values for categorical\n",
        "from collections import Counter\n",
        "print('first col')\n",
        "print(Counter(features_dataset[0]).keys())\n",
        "print(Counter(features_dataset[0]).values())\n",
        "print('second col')\n",
        "print(Counter(features_dataset[1]).keys())\n",
        "print(Counter(features_dataset[1]).values())\n",
        "print('third col')\n",
        "print(Counter(features_dataset[2]).keys())\n",
        "print(Counter(features_dataset[2]).values())"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "first col\n",
            "dict_keys(['right', 'left'])\n",
            "dict_values([61, 79])\n",
            "second col\n",
            "dict_keys(['type_3', 'type_2', 'type_1'])\n",
            "dict_values([64, 32, 44])\n",
            "third col\n",
            "dict_keys(['green', 'blue', 'red'])\n",
            "dict_values([51, 36, 53])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "neMt0wIm1hjl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Convert categorical and labels to one-hot"
      ]
    },
    {
      "metadata": {
        "id": "HgHY0v7t-cM1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#converts the labels to one-hot\n",
        "y_cat = to_categorical(labels_dataset.iloc[:,:]) \n",
        "\n",
        "# Get one hot encoding of columns 1-3 in the feature dataset\n",
        "one_hot = pd.get_dummies(features_dataset.iloc[:,:3])\n",
        "\n",
        "# Drop columns 1-3 as it is now encoded\n",
        "features_dataset = features_dataset.drop(features_dataset.iloc[:,:3],axis = 1)\n",
        "\n",
        "# Join the encoded df\n",
        "features_dataset = features_dataset.join(one_hot)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "__-tFMaoVnVV",
        "colab_type": "code",
        "outputId": "c036a777-5b98-44df-b303-8bdafee6d2f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "#Check new shape\n",
        "features_dataset.shape"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(140, 908)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "metadata": {
        "id": "WtoWCgI610yk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Prepare Test and Train Data\n"
      ]
    },
    {
      "metadata": {
        "id": "nU7jUcZ75n8R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "features, labels = features_dataset, y_cat\n",
        "\n",
        "train_features, test_features, train_labels, test_labels = train_test_split(\n",
        "        features, labels,\n",
        "        train_size=0.7, #70% training and 30% testing \n",
        "        test_size=0.3,\n",
        "        random_state=12, #Allow for reproducible results \n",
        "        # keep same proportion of 'target' in test and target data\n",
        "        stratify=labels\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VTnRWvE32DAU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Grid search for hyperparameters"
      ]
    },
    {
      "metadata": {
        "id": "c-A05JfG--ZW",
        "colab_type": "code",
        "outputId": "5c1a07b7-f892-44fe-9bff-a74f410915e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1437
        }
      },
      "cell_type": "code",
      "source": [
        "#Tune the batch size and epochs\n",
        "\n",
        "#Define model\n",
        "def create_model():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(5,input_shape=(908,), activation='relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(7, activation='relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(3, activation='softmax'))\n",
        "  #Compile\n",
        "  model.compile('adam', 'categorical_crossentropy', metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "# create model\n",
        "model = KerasClassifier(build_fn=create_model, verbose=1)\n",
        "# define the grid search parameters for Batch Size and Number of Epochs\n",
        "batch_size = [5, 10, 15, 20, 25]\n",
        "epochs = [10, 20, 30, 40]\n",
        "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1)\n",
        "grid_result = grid.fit(train_features, train_labels, validation_data=(test_features, test_labels),verbose=1)\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
            "  warnings.warn(CV_WARNING, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 98 samples, validate on 42 samples\n",
            "Epoch 1/20\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 1.4079 - acc: 0.4796 - val_loss: 1.3979 - val_acc: 0.4048\n",
            "Epoch 2/20\n",
            "98/98 [==============================] - 0s 274us/step - loss: 1.4177 - acc: 0.5408 - val_loss: 1.2768 - val_acc: 0.4762\n",
            "Epoch 3/20\n",
            "98/98 [==============================] - 0s 279us/step - loss: 1.3880 - acc: 0.5000 - val_loss: 1.1525 - val_acc: 0.5238\n",
            "Epoch 4/20\n",
            "98/98 [==============================] - 0s 298us/step - loss: 1.4751 - acc: 0.5408 - val_loss: 1.1029 - val_acc: 0.5238\n",
            "Epoch 5/20\n",
            "98/98 [==============================] - 0s 280us/step - loss: 1.1681 - acc: 0.5714 - val_loss: 1.0972 - val_acc: 0.5238\n",
            "Epoch 6/20\n",
            "98/98 [==============================] - 0s 292us/step - loss: 1.0741 - acc: 0.5204 - val_loss: 1.0905 - val_acc: 0.5238\n",
            "Epoch 7/20\n",
            "98/98 [==============================] - 0s 310us/step - loss: 1.0518 - acc: 0.5510 - val_loss: 1.0866 - val_acc: 0.5714\n",
            "Epoch 8/20\n",
            "98/98 [==============================] - 0s 278us/step - loss: 1.0171 - acc: 0.5306 - val_loss: 1.0922 - val_acc: 0.5714\n",
            "Epoch 9/20\n",
            "98/98 [==============================] - 0s 295us/step - loss: 1.0220 - acc: 0.5714 - val_loss: 1.0919 - val_acc: 0.5476\n",
            "Epoch 10/20\n",
            "98/98 [==============================] - 0s 291us/step - loss: 0.9240 - acc: 0.5612 - val_loss: 1.1012 - val_acc: 0.5476\n",
            "Epoch 11/20\n",
            "98/98 [==============================] - 0s 289us/step - loss: 0.9901 - acc: 0.5408 - val_loss: 1.1003 - val_acc: 0.5238\n",
            "Epoch 12/20\n",
            "98/98 [==============================] - 0s 282us/step - loss: 0.9941 - acc: 0.5408 - val_loss: 1.0897 - val_acc: 0.5476\n",
            "Epoch 13/20\n",
            "98/98 [==============================] - 0s 300us/step - loss: 0.9368 - acc: 0.5714 - val_loss: 1.0903 - val_acc: 0.5476\n",
            "Epoch 14/20\n",
            "98/98 [==============================] - 0s 266us/step - loss: 0.9553 - acc: 0.5714 - val_loss: 1.1009 - val_acc: 0.5476\n",
            "Epoch 15/20\n",
            "98/98 [==============================] - 0s 282us/step - loss: 0.9212 - acc: 0.5408 - val_loss: 1.1208 - val_acc: 0.5476\n",
            "Epoch 16/20\n",
            "98/98 [==============================] - 0s 279us/step - loss: 0.9154 - acc: 0.5714 - val_loss: 1.1350 - val_acc: 0.5238\n",
            "Epoch 17/20\n",
            "98/98 [==============================] - 0s 300us/step - loss: 0.9841 - acc: 0.5102 - val_loss: 1.1545 - val_acc: 0.5238\n",
            "Epoch 18/20\n",
            "98/98 [==============================] - 0s 314us/step - loss: 0.9711 - acc: 0.5408 - val_loss: 1.2005 - val_acc: 0.5238\n",
            "Epoch 19/20\n",
            "98/98 [==============================] - 0s 288us/step - loss: 0.9597 - acc: 0.5816 - val_loss: 1.2293 - val_acc: 0.5238\n",
            "Epoch 20/20\n",
            "98/98 [==============================] - 0s 285us/step - loss: 0.9459 - acc: 0.5918 - val_loss: 1.2229 - val_acc: 0.5238\n",
            "Best: 0.612245 using {'batch_size': 25, 'epochs': 20}\n",
            "0.500000 (0.069856) with: {'batch_size': 5, 'epochs': 10}\n",
            "0.540816 (0.019560) with: {'batch_size': 5, 'epochs': 20}\n",
            "0.530612 (0.033338) with: {'batch_size': 5, 'epochs': 30}\n",
            "0.571429 (0.050124) with: {'batch_size': 5, 'epochs': 40}\n",
            "0.520408 (0.039917) with: {'batch_size': 10, 'epochs': 10}\n",
            "0.500000 (0.045261) with: {'batch_size': 10, 'epochs': 20}\n",
            "0.591837 (0.062185) with: {'batch_size': 10, 'epochs': 30}\n",
            "0.571429 (0.046628) with: {'batch_size': 10, 'epochs': 40}\n",
            "0.530612 (0.070271) with: {'batch_size': 15, 'epochs': 10}\n",
            "0.540816 (0.059922) with: {'batch_size': 15, 'epochs': 20}\n",
            "0.591837 (0.075133) with: {'batch_size': 15, 'epochs': 30}\n",
            "0.581633 (0.039610) with: {'batch_size': 15, 'epochs': 40}\n",
            "0.479592 (0.061381) with: {'batch_size': 20, 'epochs': 10}\n",
            "0.540816 (0.044463) with: {'batch_size': 20, 'epochs': 20}\n",
            "0.571429 (0.025634) with: {'batch_size': 20, 'epochs': 30}\n",
            "0.551020 (0.007993) with: {'batch_size': 20, 'epochs': 40}\n",
            "0.561224 (0.032466) with: {'batch_size': 25, 'epochs': 10}\n",
            "0.612245 (0.069311) with: {'batch_size': 25, 'epochs': 20}\n",
            "0.540816 (0.070653) with: {'batch_size': 25, 'epochs': 30}\n",
            "0.551020 (0.050375) with: {'batch_size': 25, 'epochs': 40}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tpyAxPCSfh7y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1037
        },
        "outputId": "6e491970-28ff-4bc2-d379-b37308c1c53d"
      },
      "cell_type": "code",
      "source": [
        "#Tune the Training Optimization Algorithm\n",
        "\n",
        "def create_model(optimizer='adam'):\n",
        "  model = Sequential()\n",
        "  model.add(Dense(5,input_shape=(908,), activation='relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(7, activation='relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(3, activation='softmax'))\n",
        "  #Compile\n",
        "  model.compile('adam', 'categorical_crossentropy', metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "# create model\n",
        "model = KerasClassifier(build_fn=create_model, epochs=20, batch_size=25, verbose=0)\n",
        "\n",
        "# define the grid search parameters for Batch Size and Number of Epochs\n",
        "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
        "param_grid = dict(optimizer=optimizer)\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1)\n",
        "grid_result = grid.fit(train_features, train_labels, validation_data=(test_features, test_labels),verbose=1)\n",
        "\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
            "  warnings.warn(CV_WARNING, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 98 samples, validate on 42 samples\n",
            "Epoch 1/20\n",
            "98/98 [==============================] - 3s 31ms/step - loss: 1.4598 - acc: 0.4388 - val_loss: 1.3296 - val_acc: 0.3810\n",
            "Epoch 2/20\n",
            "98/98 [==============================] - 0s 318us/step - loss: 1.3192 - acc: 0.4694 - val_loss: 1.2722 - val_acc: 0.3810\n",
            "Epoch 3/20\n",
            "98/98 [==============================] - 0s 313us/step - loss: 1.2085 - acc: 0.5102 - val_loss: 1.2406 - val_acc: 0.3810\n",
            "Epoch 4/20\n",
            "98/98 [==============================] - 0s 291us/step - loss: 1.2635 - acc: 0.5204 - val_loss: 1.2411 - val_acc: 0.3810\n",
            "Epoch 5/20\n",
            "98/98 [==============================] - 0s 284us/step - loss: 1.0218 - acc: 0.5102 - val_loss: 1.2445 - val_acc: 0.4286\n",
            "Epoch 6/20\n",
            "98/98 [==============================] - 0s 298us/step - loss: 1.0142 - acc: 0.5612 - val_loss: 1.2328 - val_acc: 0.4524\n",
            "Epoch 7/20\n",
            "98/98 [==============================] - 0s 334us/step - loss: 1.0739 - acc: 0.5306 - val_loss: 1.2232 - val_acc: 0.4762\n",
            "Epoch 8/20\n",
            "98/98 [==============================] - 0s 419us/step - loss: 1.0053 - acc: 0.5408 - val_loss: 1.2080 - val_acc: 0.5000\n",
            "Epoch 9/20\n",
            "98/98 [==============================] - 0s 311us/step - loss: 1.1533 - acc: 0.5510 - val_loss: 1.1920 - val_acc: 0.5238\n",
            "Epoch 10/20\n",
            "98/98 [==============================] - 0s 300us/step - loss: 1.1299 - acc: 0.5306 - val_loss: 1.1639 - val_acc: 0.5714\n",
            "Epoch 11/20\n",
            "98/98 [==============================] - 0s 326us/step - loss: 0.9804 - acc: 0.5918 - val_loss: 1.1394 - val_acc: 0.5714\n",
            "Epoch 12/20\n",
            "98/98 [==============================] - 0s 300us/step - loss: 0.9772 - acc: 0.5306 - val_loss: 1.1138 - val_acc: 0.5714\n",
            "Epoch 13/20\n",
            "98/98 [==============================] - 0s 307us/step - loss: 0.9723 - acc: 0.5612 - val_loss: 1.0943 - val_acc: 0.5714\n",
            "Epoch 14/20\n",
            "98/98 [==============================] - 0s 316us/step - loss: 0.9405 - acc: 0.5714 - val_loss: 1.0713 - val_acc: 0.5714\n",
            "Epoch 15/20\n",
            "98/98 [==============================] - 0s 348us/step - loss: 0.9910 - acc: 0.5000 - val_loss: 1.0664 - val_acc: 0.5714\n",
            "Epoch 16/20\n",
            "98/98 [==============================] - 0s 352us/step - loss: 0.9527 - acc: 0.5714 - val_loss: 1.0669 - val_acc: 0.5952\n",
            "Epoch 17/20\n",
            "98/98 [==============================] - 0s 313us/step - loss: 0.9878 - acc: 0.5306 - val_loss: 1.0677 - val_acc: 0.5952\n",
            "Epoch 18/20\n",
            "98/98 [==============================] - 0s 295us/step - loss: 0.9822 - acc: 0.5408 - val_loss: 1.0756 - val_acc: 0.5952\n",
            "Epoch 19/20\n",
            "98/98 [==============================] - 0s 317us/step - loss: 0.9201 - acc: 0.5816 - val_loss: 1.0801 - val_acc: 0.5952\n",
            "Epoch 20/20\n",
            "98/98 [==============================] - 0s 348us/step - loss: 0.9280 - acc: 0.5510 - val_loss: 1.0852 - val_acc: 0.5952\n",
            "Best: 0.571429 using {'optimizer': 'Adagrad'}\n",
            "0.530612 (0.076144) with: {'optimizer': 'SGD'}\n",
            "0.500000 (0.037302) with: {'optimizer': 'RMSprop'}\n",
            "0.571429 (0.050124) with: {'optimizer': 'Adagrad'}\n",
            "0.540816 (0.040242) with: {'optimizer': 'Adadelta'}\n",
            "0.489796 (0.047166) with: {'optimizer': 'Adam'}\n",
            "0.520408 (0.056802) with: {'optimizer': 'Adamax'}\n",
            "0.479592 (0.061381) with: {'optimizer': 'Nadam'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Vk_4kZe9iD6x",
        "colab_type": "code",
        "outputId": "7bafd767-3a97-4f45-e325-856af7a22bac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3728
        }
      },
      "cell_type": "code",
      "source": [
        "# Tune the Number of Neurons in the Hidden Layer\n",
        "\n",
        "def create_model(neurons1=1,neurons2=1):\n",
        "  model = Sequential()\n",
        "  model.add(Dense(neurons1,input_shape=(908,), activation='relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(neurons2, activation='relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(3, activation='softmax'))\n",
        "  \n",
        "  #Compile\n",
        "  model.compile('RMSprop', 'categorical_crossentropy', metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "# create model\n",
        "model = KerasClassifier(build_fn=create_model, epochs=20, batch_size=25, verbose=0)\n",
        "\n",
        "# define the grid search parameters\n",
        "neurons1 = [3,4 ,5,6,7,8,9,10,11,12,13,14 ,15,16]\n",
        "neurons2 = [3,4 ,5,6,7,8,9,10,11,12,13,14,15,16]\n",
        "\n",
        "param_grid = dict(neurons1=neurons1, neurons2=neurons2 )\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1)\n",
        "grid_result = grid.fit(train_features, train_labels, validation_data=(test_features, test_labels),verbose=0)\n",
        "\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
            "  warnings.warn(CV_WARNING, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best: 0.602041 using {'neurons1': 3, 'neurons2': 10}\n",
            "0.540816 (0.050181) with: {'neurons1': 3, 'neurons2': 3}\n",
            "0.591837 (0.054836) with: {'neurons1': 3, 'neurons2': 4}\n",
            "0.520408 (0.025989) with: {'neurons1': 3, 'neurons2': 5}\n",
            "0.479592 (0.063774) with: {'neurons1': 3, 'neurons2': 6}\n",
            "0.571429 (0.006217) with: {'neurons1': 3, 'neurons2': 7}\n",
            "0.500000 (0.057318) with: {'neurons1': 3, 'neurons2': 8}\n",
            "0.500000 (0.126231) with: {'neurons1': 3, 'neurons2': 9}\n",
            "0.602041 (0.040584) with: {'neurons1': 3, 'neurons2': 10}\n",
            "0.540816 (0.070653) with: {'neurons1': 3, 'neurons2': 11}\n",
            "0.520408 (0.025989) with: {'neurons1': 3, 'neurons2': 12}\n",
            "0.510204 (0.047166) with: {'neurons1': 3, 'neurons2': 13}\n",
            "0.561224 (0.075383) with: {'neurons1': 3, 'neurons2': 14}\n",
            "0.469388 (0.054112) with: {'neurons1': 3, 'neurons2': 15}\n",
            "0.510204 (0.050241) with: {'neurons1': 3, 'neurons2': 16}\n",
            "0.520408 (0.157707) with: {'neurons1': 4, 'neurons2': 3}\n",
            "0.479592 (0.025989) with: {'neurons1': 4, 'neurons2': 4}\n",
            "0.510204 (0.102451) with: {'neurons1': 4, 'neurons2': 5}\n",
            "0.520408 (0.007549) with: {'neurons1': 4, 'neurons2': 6}\n",
            "0.489796 (0.031429) with: {'neurons1': 4, 'neurons2': 7}\n",
            "0.520408 (0.120469) with: {'neurons1': 4, 'neurons2': 8}\n",
            "0.469388 (0.056982) with: {'neurons1': 4, 'neurons2': 9}\n",
            "0.448980 (0.108692) with: {'neurons1': 4, 'neurons2': 10}\n",
            "0.540816 (0.112921) with: {'neurons1': 4, 'neurons2': 11}\n",
            "0.520408 (0.031837) with: {'neurons1': 4, 'neurons2': 12}\n",
            "0.408163 (0.032182) with: {'neurons1': 4, 'neurons2': 13}\n",
            "0.520408 (0.068733) with: {'neurons1': 4, 'neurons2': 14}\n",
            "0.510204 (0.063874) with: {'neurons1': 4, 'neurons2': 15}\n",
            "0.530612 (0.106601) with: {'neurons1': 4, 'neurons2': 16}\n",
            "0.510204 (0.044096) with: {'neurons1': 5, 'neurons2': 3}\n",
            "0.510204 (0.061642) with: {'neurons1': 5, 'neurons2': 4}\n",
            "0.438776 (0.044408) with: {'neurons1': 5, 'neurons2': 5}\n",
            "0.459184 (0.139697) with: {'neurons1': 5, 'neurons2': 6}\n",
            "0.540816 (0.068359) with: {'neurons1': 5, 'neurons2': 7}\n",
            "0.540816 (0.006661) with: {'neurons1': 5, 'neurons2': 8}\n",
            "0.540816 (0.006661) with: {'neurons1': 5, 'neurons2': 9}\n",
            "0.510204 (0.099726) with: {'neurons1': 5, 'neurons2': 10}\n",
            "0.540816 (0.025745) with: {'neurons1': 5, 'neurons2': 11}\n",
            "0.530612 (0.076144) with: {'neurons1': 5, 'neurons2': 12}\n",
            "0.520408 (0.106867) with: {'neurons1': 5, 'neurons2': 13}\n",
            "0.540816 (0.019560) with: {'neurons1': 5, 'neurons2': 14}\n",
            "0.591837 (0.062185) with: {'neurons1': 5, 'neurons2': 15}\n",
            "0.520408 (0.081826) with: {'neurons1': 5, 'neurons2': 16}\n",
            "0.530612 (0.033338) with: {'neurons1': 6, 'neurons2': 3}\n",
            "0.581633 (0.050447) with: {'neurons1': 6, 'neurons2': 4}\n",
            "0.520408 (0.047439) with: {'neurons1': 6, 'neurons2': 5}\n",
            "0.591837 (0.054836) with: {'neurons1': 6, 'neurons2': 6}\n",
            "0.561224 (0.044408) with: {'neurons1': 6, 'neurons2': 7}\n",
            "0.530612 (0.033338) with: {'neurons1': 6, 'neurons2': 8}\n",
            "0.428571 (0.136351) with: {'neurons1': 6, 'neurons2': 9}\n",
            "0.520408 (0.025989) with: {'neurons1': 6, 'neurons2': 10}\n",
            "0.459184 (0.081036) with: {'neurons1': 6, 'neurons2': 11}\n",
            "0.571429 (0.096515) with: {'neurons1': 6, 'neurons2': 12}\n",
            "0.530612 (0.112037) with: {'neurons1': 6, 'neurons2': 13}\n",
            "0.479592 (0.059054) with: {'neurons1': 6, 'neurons2': 14}\n",
            "0.520408 (0.031837) with: {'neurons1': 6, 'neurons2': 15}\n",
            "0.448980 (0.063676) with: {'neurons1': 6, 'neurons2': 16}\n",
            "0.489796 (0.095418) with: {'neurons1': 7, 'neurons2': 3}\n",
            "0.489796 (0.083713) with: {'neurons1': 7, 'neurons2': 4}\n",
            "0.540816 (0.061905) with: {'neurons1': 7, 'neurons2': 5}\n",
            "0.510204 (0.044096) with: {'neurons1': 7, 'neurons2': 6}\n",
            "0.602041 (0.083610) with: {'neurons1': 7, 'neurons2': 7}\n",
            "0.438776 (0.062177) with: {'neurons1': 7, 'neurons2': 8}\n",
            "0.510204 (0.068545) with: {'neurons1': 7, 'neurons2': 9}\n",
            "0.510204 (0.025863) with: {'neurons1': 7, 'neurons2': 10}\n",
            "0.551020 (0.105627) with: {'neurons1': 7, 'neurons2': 11}\n",
            "0.500000 (0.147418) with: {'neurons1': 7, 'neurons2': 12}\n",
            "0.530612 (0.054112) with: {'neurons1': 7, 'neurons2': 13}\n",
            "0.571429 (0.044832) with: {'neurons1': 7, 'neurons2': 14}\n",
            "0.479592 (0.063774) with: {'neurons1': 7, 'neurons2': 15}\n",
            "0.316327 (0.031354) with: {'neurons1': 7, 'neurons2': 16}\n",
            "0.571429 (0.050124) with: {'neurons1': 8, 'neurons2': 3}\n",
            "0.479592 (0.157707) with: {'neurons1': 8, 'neurons2': 4}\n",
            "0.561224 (0.032466) with: {'neurons1': 8, 'neurons2': 5}\n",
            "0.428571 (0.040411) with: {'neurons1': 8, 'neurons2': 6}\n",
            "0.448980 (0.026121) with: {'neurons1': 8, 'neurons2': 7}\n",
            "0.520408 (0.018882) with: {'neurons1': 8, 'neurons2': 8}\n",
            "0.489796 (0.050241) with: {'neurons1': 8, 'neurons2': 9}\n",
            "0.459184 (0.036858) with: {'neurons1': 8, 'neurons2': 10}\n",
            "0.459184 (0.040242) with: {'neurons1': 8, 'neurons2': 11}\n",
            "0.469388 (0.012442) with: {'neurons1': 8, 'neurons2': 12}\n",
            "0.500000 (0.045261) with: {'neurons1': 8, 'neurons2': 13}\n",
            "0.520408 (0.031837) with: {'neurons1': 8, 'neurons2': 14}\n",
            "0.540816 (0.040242) with: {'neurons1': 8, 'neurons2': 15}\n",
            "0.551020 (0.050375) with: {'neurons1': 8, 'neurons2': 16}\n",
            "0.479592 (0.039917) with: {'neurons1': 9, 'neurons2': 3}\n",
            "0.469388 (0.012442) with: {'neurons1': 9, 'neurons2': 4}\n",
            "0.510204 (0.047166) with: {'neurons1': 9, 'neurons2': 5}\n",
            "0.469388 (0.021316) with: {'neurons1': 9, 'neurons2': 6}\n",
            "0.510204 (0.105929) with: {'neurons1': 9, 'neurons2': 7}\n",
            "0.540816 (0.085447) with: {'neurons1': 9, 'neurons2': 8}\n",
            "0.500000 (0.037302) with: {'neurons1': 9, 'neurons2': 9}\n",
            "0.459184 (0.056005) with: {'neurons1': 9, 'neurons2': 10}\n",
            "0.500000 (0.012434) with: {'neurons1': 9, 'neurons2': 11}\n",
            "0.551020 (0.057201) with: {'neurons1': 9, 'neurons2': 12}\n",
            "0.418367 (0.039610) with: {'neurons1': 9, 'neurons2': 13}\n",
            "0.500000 (0.082068) with: {'neurons1': 9, 'neurons2': 14}\n",
            "0.438776 (0.101639) with: {'neurons1': 9, 'neurons2': 15}\n",
            "0.459184 (0.044463) with: {'neurons1': 9, 'neurons2': 16}\n",
            "0.438776 (0.164637) with: {'neurons1': 10, 'neurons2': 3}\n",
            "0.571429 (0.109991) with: {'neurons1': 10, 'neurons2': 4}\n",
            "0.479592 (0.081826) with: {'neurons1': 10, 'neurons2': 5}\n",
            "0.459184 (0.115460) with: {'neurons1': 10, 'neurons2': 6}\n",
            "0.489796 (0.031429) with: {'neurons1': 10, 'neurons2': 7}\n",
            "0.551020 (0.082865) with: {'neurons1': 10, 'neurons2': 8}\n",
            "0.459184 (0.081036) with: {'neurons1': 10, 'neurons2': 9}\n",
            "0.581633 (0.090914) with: {'neurons1': 10, 'neurons2': 10}\n",
            "0.428571 (0.019904) with: {'neurons1': 10, 'neurons2': 11}\n",
            "0.489796 (0.031429) with: {'neurons1': 10, 'neurons2': 12}\n",
            "0.428571 (0.049736) with: {'neurons1': 10, 'neurons2': 13}\n",
            "0.571429 (0.006217) with: {'neurons1': 10, 'neurons2': 14}\n",
            "0.530612 (0.077590) with: {'neurons1': 10, 'neurons2': 15}\n",
            "0.520408 (0.047439) with: {'neurons1': 10, 'neurons2': 16}\n",
            "0.510204 (0.044096) with: {'neurons1': 11, 'neurons2': 3}\n",
            "0.530612 (0.112037) with: {'neurons1': 11, 'neurons2': 4}\n",
            "0.510204 (0.102451) with: {'neurons1': 11, 'neurons2': 5}\n",
            "0.551020 (0.047715) with: {'neurons1': 11, 'neurons2': 6}\n",
            "0.540816 (0.059922) with: {'neurons1': 11, 'neurons2': 7}\n",
            "0.510204 (0.061642) with: {'neurons1': 11, 'neurons2': 8}\n",
            "0.459184 (0.081036) with: {'neurons1': 11, 'neurons2': 9}\n",
            "0.489796 (0.019219) with: {'neurons1': 11, 'neurons2': 10}\n",
            "0.551020 (0.093391) with: {'neurons1': 11, 'neurons2': 11}\n",
            "0.479592 (0.109016) with: {'neurons1': 11, 'neurons2': 12}\n",
            "0.561224 (0.022648) with: {'neurons1': 11, 'neurons2': 13}\n",
            "0.377551 (0.076921) with: {'neurons1': 11, 'neurons2': 14}\n",
            "0.510204 (0.069106) with: {'neurons1': 11, 'neurons2': 15}\n",
            "0.367347 (0.085410) with: {'neurons1': 11, 'neurons2': 16}\n",
            "0.551020 (0.026121) with: {'neurons1': 12, 'neurons2': 3}\n",
            "0.540816 (0.050181) with: {'neurons1': 12, 'neurons2': 4}\n",
            "0.520408 (0.007549) with: {'neurons1': 12, 'neurons2': 5}\n",
            "0.500000 (0.045261) with: {'neurons1': 12, 'neurons2': 6}\n",
            "0.500000 (0.099132) with: {'neurons1': 12, 'neurons2': 7}\n",
            "0.438776 (0.069026) with: {'neurons1': 12, 'neurons2': 8}\n",
            "0.489796 (0.031429) with: {'neurons1': 12, 'neurons2': 9}\n",
            "0.540816 (0.099696) with: {'neurons1': 12, 'neurons2': 10}\n",
            "0.408163 (0.037326) with: {'neurons1': 12, 'neurons2': 11}\n",
            "0.469388 (0.107324) with: {'neurons1': 12, 'neurons2': 12}\n",
            "0.561224 (0.077469) with: {'neurons1': 12, 'neurons2': 13}\n",
            "0.448980 (0.026121) with: {'neurons1': 12, 'neurons2': 14}\n",
            "0.418367 (0.088052) with: {'neurons1': 12, 'neurons2': 15}\n",
            "0.428571 (0.084561) with: {'neurons1': 12, 'neurons2': 16}\n",
            "0.408163 (0.186102) with: {'neurons1': 13, 'neurons2': 3}\n",
            "0.561225 (0.033636) with: {'neurons1': 13, 'neurons2': 4}\n",
            "0.489796 (0.031429) with: {'neurons1': 13, 'neurons2': 5}\n",
            "0.540816 (0.081036) with: {'neurons1': 13, 'neurons2': 6}\n",
            "0.438776 (0.081363) with: {'neurons1': 13, 'neurons2': 7}\n",
            "0.561225 (0.142318) with: {'neurons1': 13, 'neurons2': 8}\n",
            "0.561224 (0.056647) with: {'neurons1': 13, 'neurons2': 9}\n",
            "0.418367 (0.067989) with: {'neurons1': 13, 'neurons2': 10}\n",
            "0.500000 (0.045261) with: {'neurons1': 13, 'neurons2': 11}\n",
            "0.500000 (0.069856) with: {'neurons1': 13, 'neurons2': 12}\n",
            "0.551020 (0.018550) with: {'neurons1': 13, 'neurons2': 13}\n",
            "0.479592 (0.039917) with: {'neurons1': 13, 'neurons2': 14}\n",
            "0.530612 (0.098841) with: {'neurons1': 13, 'neurons2': 15}\n",
            "0.520408 (0.068733) with: {'neurons1': 13, 'neurons2': 16}\n",
            "0.551020 (0.050375) with: {'neurons1': 14, 'neurons2': 3}\n",
            "0.530612 (0.033338) with: {'neurons1': 14, 'neurons2': 4}\n",
            "0.459184 (0.006661) with: {'neurons1': 14, 'neurons2': 5}\n",
            "0.500000 (0.012434) with: {'neurons1': 14, 'neurons2': 6}\n",
            "0.561224 (0.069026) with: {'neurons1': 14, 'neurons2': 7}\n",
            "0.489796 (0.050241) with: {'neurons1': 14, 'neurons2': 8}\n",
            "0.540816 (0.063978) with: {'neurons1': 14, 'neurons2': 9}\n",
            "0.459184 (0.116127) with: {'neurons1': 14, 'neurons2': 10}\n",
            "0.489796 (0.044096) with: {'neurons1': 14, 'neurons2': 11}\n",
            "0.540816 (0.019560) with: {'neurons1': 14, 'neurons2': 12}\n",
            "0.551020 (0.051513) with: {'neurons1': 14, 'neurons2': 13}\n",
            "0.397959 (0.089418) with: {'neurons1': 14, 'neurons2': 14}\n",
            "0.469388 (0.131554) with: {'neurons1': 14, 'neurons2': 15}\n",
            "0.520408 (0.050306) with: {'neurons1': 14, 'neurons2': 16}\n",
            "0.591837 (0.020427) with: {'neurons1': 15, 'neurons2': 3}\n",
            "0.551020 (0.032247) with: {'neurons1': 15, 'neurons2': 4}\n",
            "0.448980 (0.047715) with: {'neurons1': 15, 'neurons2': 5}\n",
            "0.418367 (0.057602) with: {'neurons1': 15, 'neurons2': 6}\n",
            "0.479592 (0.043730) with: {'neurons1': 15, 'neurons2': 7}\n",
            "0.479592 (0.051069) with: {'neurons1': 15, 'neurons2': 8}\n",
            "0.438776 (0.106241) with: {'neurons1': 15, 'neurons2': 9}\n",
            "0.500000 (0.037302) with: {'neurons1': 15, 'neurons2': 10}\n",
            "0.561224 (0.087043) with: {'neurons1': 15, 'neurons2': 11}\n",
            "0.530612 (0.070271) with: {'neurons1': 15, 'neurons2': 12}\n",
            "0.510204 (0.056403) with: {'neurons1': 15, 'neurons2': 13}\n",
            "0.367347 (0.114803) with: {'neurons1': 15, 'neurons2': 14}\n",
            "0.561224 (0.097713) with: {'neurons1': 15, 'neurons2': 15}\n",
            "0.459184 (0.081036) with: {'neurons1': 15, 'neurons2': 16}\n",
            "0.571429 (0.050124) with: {'neurons1': 16, 'neurons2': 3}\n",
            "0.581633 (0.103955) with: {'neurons1': 16, 'neurons2': 4}\n",
            "0.530612 (0.082421) with: {'neurons1': 16, 'neurons2': 5}\n",
            "0.500000 (0.120071) with: {'neurons1': 16, 'neurons2': 6}\n",
            "0.459184 (0.099696) with: {'neurons1': 16, 'neurons2': 7}\n",
            "0.500000 (0.062171) with: {'neurons1': 16, 'neurons2': 8}\n",
            "0.510204 (0.085143) with: {'neurons1': 16, 'neurons2': 9}\n",
            "0.489796 (0.044096) with: {'neurons1': 16, 'neurons2': 10}\n",
            "0.500000 (0.099132) with: {'neurons1': 16, 'neurons2': 11}\n",
            "0.591837 (0.076661) with: {'neurons1': 16, 'neurons2': 12}\n",
            "0.500000 (0.069856) with: {'neurons1': 16, 'neurons2': 13}\n",
            "0.397959 (0.112357) with: {'neurons1': 16, 'neurons2': 14}\n",
            "0.418367 (0.169646) with: {'neurons1': 16, 'neurons2': 15}\n",
            "0.469388 (0.069441) with: {'neurons1': 16, 'neurons2': 16}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "blQVBdJm_bUU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Run the model with the optimal parameters\n",
        "model = Sequential()\n",
        "model.add(Dense(5,input_shape=(908,), activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(5, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "#Compile\n",
        "model.compile('RMSprop', 'categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# checkpoint\n",
        "filepath=\"weights.best.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=0, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SCSDeak8_fdT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#fit\n",
        "history=model.fit(train_features, train_labels, validation_data=(test_features, test_labels),verbose=1,epochs=251, callbacks=callbacks_list) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Yyem-2d6bjuh",
        "colab_type": "code",
        "outputId": "7ef590ef-7544-48b7-8fcb-9d02821ad377",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "cell_type": "code",
      "source": [
        "#Virtualize Training\n",
        "fig, ax = plt.subplots(2,1)\n",
        "ax[0].plot(history.history['acc'], color='b', label=\"Training accuracy\")\n",
        "ax[0].plot(history.history['val_acc'], color='r', label=\"validation accuracy\",axes =ax[0])\n",
        "legend = ax[0].legend(loc='best', shadow=True)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAegAAAFKCAYAAADWhMzpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x396 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "pKE6dtuK_F7d",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Testing the model on the entire dataset with the best weights"
      ]
    },
    {
      "metadata": {
        "id": "tHSVVCA8p8wq",
        "colab_type": "code",
        "outputId": "24040b70-8e27-4bf6-d3d0-ceae2e761042",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "#Loading Check-Pointed\n",
        "#The checkpoint only includes the model weights. It assumes you know the network structure.\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(5,input_shape=(908,), activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(5, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "# load weights\n",
        "model.load_weights(\"weights.best.hdf5\")\n",
        "\n",
        "#Compile\n",
        "model.compile('RMSprop', 'categorical_crossentropy', metrics=['accuracy'])\n",
        "print(\"Created model and loaded weights from file\")\n",
        "\n",
        "# estimate accuracy on whole dataset using loaded weights\n",
        "scores = model.evaluate(train_features, train_labels, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Created model and loaded weights from file\n",
            "acc: 77.55%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dh2siqkT_MO0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Preparing testing data"
      ]
    },
    {
      "metadata": {
        "id": "341iHUOtQTwS",
        "colab_type": "code",
        "outputId": "2aa1976f-ac72-459f-f338-baabe910c954",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "#Load testing data\n",
        "testing_data=pd.read_csv('test_features.csv', header=None)\n",
        "print('Test dataset shape is: ' + str(testing_data.shape))\n"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test dataset shape is: (560, 903)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5X58RLkDtDU_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Get one hot encoding of columns 1-3 in the testing dataset\n",
        "one_hot = pd.get_dummies(testing_data.iloc[:,:3])\n",
        "\n",
        "# Drop columns 1-3 as it is now encoded\n",
        "testing_data = testing_data.drop(testing_data.iloc[:,:3],axis = 1)\n",
        "\n",
        "# Join the encoded df\n",
        "testing_data = testing_data.join(one_hot)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iN69U-Gt_Rph",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Predict"
      ]
    },
    {
      "metadata": {
        "id": "YerEguaCrJGn",
        "colab_type": "code",
        "outputId": "b873b6ae-8f52-47a4-d27b-dea1678a9b61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "#After the model has been train we can make predictions\n",
        "\n",
        "y_pred = model.predict(testing_data)\n",
        "y_pred.shape"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(560, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "metadata": {
        "id": "RA0p-g1MsBMR",
        "colab_type": "code",
        "outputId": "b56e3741-7d3f-45a5-9db4-b5f4d3f3b125",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.24498188, 0.42839113, 0.326627  ],\n",
              "       [0.01970868, 0.32594743, 0.6543439 ],\n",
              "       [0.46152616, 0.26516986, 0.273304  ],\n",
              "       ...,\n",
              "       [0.01410408, 0.2970675 , 0.68882847],\n",
              "       [0.6405557 , 0.32041278, 0.03903149],\n",
              "       [0.06898094, 0.40784532, 0.52317375]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "metadata": {
        "id": "EWOJOphP_aYx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Convert the probabilities to values\n"
      ]
    },
    {
      "metadata": {
        "id": "vGWpNrJry3c2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "answers=[]\n",
        "i=0\n",
        "\n",
        "for row in y_pred:\n",
        "  max_value = max(y_pred[i])\n",
        "  max_index = list(y_pred[i]).index(max_value)\n",
        "  answers.append(max_index)\n",
        "  i+=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZpQN2lau_hvv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Check that we got 560 answers"
      ]
    },
    {
      "metadata": {
        "id": "6rzJ1Nkq1Qy1",
        "colab_type": "code",
        "outputId": "6463917a-35fa-40de-9fb3-37adc1eb632c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "len(answers)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "560"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "metadata": {
        "id": "y3_CUz3y_wI4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Explore answers\n"
      ]
    },
    {
      "metadata": {
        "id": "Y0LAAu9r1i5h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "answers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TSg6UbBN_yWb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Save to CSV file\n"
      ]
    },
    {
      "metadata": {
        "id": "oTdNgr8U1kgE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open('test_predictions.csv', \"w\") as output:\n",
        "    writer = csv.writer(output, lineterminator='\\n')\n",
        "    for val in answers:\n",
        "        writer.writerow([val])    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2-SREZ5nBHsV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Check counts"
      ]
    },
    {
      "metadata": {
        "id": "e1kUqZ2J2FZO",
        "colab_type": "code",
        "outputId": "e03c9d01-013e-4b03-e147-2caae445e4d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "my_dict = {i:answers.count(i) for i in answers}\n",
        "print (my_dict)"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{1: 455, 2: 105}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}